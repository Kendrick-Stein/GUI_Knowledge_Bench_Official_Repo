# GUI Knowledge Bench 

> ğŸ§­ Hierarchical Evaluation Toolkit for Multimodal GUI Understanding  
> ğŸ“Š Evaluation Data: [Hugging Face Dataset](https://huggingface.co/datasets/KendrickShi/GUI-Knowledge-Bench)  
> ğŸ•¸ï¸ Website: [web](https://kendrick-stein.github.io/GUI-Knowledge-Bench-web/)  
> ğŸŒ Switch between **English** / **ä¸­æ–‡** by expanding the sections below.

---

<details open>
<summary><b>English Version ğŸ‡¬ğŸ‡§</b></summary>

## ğŸ§© Introduction

**GUI Knowledge Bench Runner** is a Python toolkit to evaluate multimodal GUI understanding across three knowledge types:

- **Interface Perception**: state information, layout semantics, widget functions  
- **Interaction Prediction**: action type and parameters, action effect (resulting screenshot)  
- **Instruction Understanding**: task completion verification and task planning  

It loads a YAML model configuration, constructs multimodal prompts (images + text), routes requests to the selected model/API, and saves results and logs for reproducible benchmarking.

---

## âš™ï¸ Features

- Structured tasks: Interface Perception, Interaction Prediction, Instruction Understanding  
- Multimodal prompt construction with optional visual annotations and knowledge prompts  
- OpenAI-compatible engine routing (Qwen compatible mode, generic proxies)  
- Concurrent execution with per-run logs and consolidated results  
- Visual annotation and action drawing utilities  
- Config-driven ablations and reproducible runs  

---

## ğŸ“ Repository Structure

| Path | Description |
|------|--------------|
| `.env` | Environment variables (API keys, dataset paths) |
| `Inference/` | Core runner and tools |
| `inference_advanced.py` | Main entry: load config, build prompts, call model, save outputs |
| `tools/load_config_tools.py` | Read YAML, enumerate test files, filter by TestingScope |
| `tools/message_gen_tools.py` | Build multimodal messages and ablations |
| `tools/draw_picture.py` | Visual annotation and GUI action drawing |
| `configs/ModelConfigList/ConfigExamples/*.yaml` | Example model configs |
| `log/{timestamp}/` | Auto-created logs per run |
| `KnowledgeBench/` | Benchmark JSON files (optional local copies) |
| `FINAL_RESULT/` | Results output |

---

## ğŸ§° Requirements and Installation

**Python 3.9+**

```bash
pip install pyyaml python-dotenv openai pydantic pillow opencv-python numpy ray
# For dataset download
pip install huggingface_hub datasets git-lfs
````

> Note: `git-lfs` also requires system-level installation.

---

## ğŸ“¦ Data Preparation

**Dataset:** [KendrickShi/GUI-Knowledge-Bench](https://huggingface.co/datasets/KendrickShi/GUI-Knowledge-Bench)

After download:

* Set `KnowledgeBenchDir` in your YAML to the directory that contains the benchmark question JSON files.
* Set `dataset_base_dir` in `.env` to a JSON list of base directories containing images.

**Download methods:**

**1ï¸âƒ£ git-lfs (recommended):**

```bash
git lfs install
git clone https://huggingface.co/datasets/KendrickShi/GUI-Knowledge-Bench datasets/GUI-Knowledge-Bench
```

**2ï¸âƒ£ huggingface_hub (Python):**

```python
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id="KendrickShi/GUI-Knowledge-Bench",
    repo_type="dataset",
    local_dir="datasets/GUI-Knowledge-Bench",
    local_dir_use_symlinks=False
)
```

**3ï¸âƒ£ datasets library:**

```python
from datasets import load_dataset
ds = load_dataset("KendrickShi/GUI-Knowledge-Bench", split="train")
```

---

## ğŸŒ Environment Variables (.env)

| Variable           | Description                                                            |
| ------------------ | ---------------------------------------------------------------------- |
| `deerapi_key`      | API key for an OpenAI-compatible proxy (e.g., DeerAPI)                 |
| `deerapi_url`      | Base URL, e.g. `https://api.deerapi.com/v1/`                           |
| `qwen_api_key`     | API key for Qwen (OpenAI-compatible mode)                              |
| `qwen_url`         | Base URL, e.g. `https://dashscope.aliyuncs.com/compatible-mode/v1`     |
| `dataset_base_dir` | JSON list of base directories, e.g. `["datasets/GUI-Knowledge-Bench"]` |

---

## ğŸ§¾ Configuration (YAML)

**Required fields:**

* `KnowledgeBenchDir`: Directory containing benchmark JSON files
* `ModelName`: Model ID (e.g., `gpt-5-chat-latest`, `qwen2.5-vl-7b-instruct`)
* `Engine`: Provider routing key (see Engine mapping)
* `ResultsDir`: Output directory
* `thinking`: Whether to include a thought field
* `MaxWorker`: Max concurrent tasks
* `kwargs`: Model call parameters (`max_tokens`, `temperature`, etc.)
* `ablation_options`: `{visual_prompt: bool, knowledge_prompt: bool}`
* `TestingScope`: Which subtasks to run

---

## ğŸ§® Engine and ModelName Mapping

Supported engines:

* **Engine: qwen** â†’ uses `qwen_api_key + qwen_url` (compatible mode)
* **Engine: deerapi_gpt** â†’ uses `deerapi_key + deerapi_url`

Special cases in `inference_advanced.py`:

```python
["grok-4-0709", "claude-sonnet-4-20250514", "gemini-2.5-pro-preview-06-05"]
```

---

## ğŸš€ Quick Start Examples

**YAML Example**

```yaml
KnowledgeBenchDir: datasets/GUI-Knowledge-Bench/questions
ModelName: gpt-5-chat-latest
Engine: deerapi_gpt
ResultsDir: FINAL_RESULT
thinking: false
MaxWorker: 4
kwargs:
  max_tokens: 1024
  temperature: 0.2
  top_p: 0.9
  timeout: 120
ablation_options:
  visual_prompt: true
  knowledge_prompt: true
TestingScope:
  - InterfacePerception
  - InteractionPrediction
  - InstructionUnderstanding
```

`.env`

```bash
dataset_base_dir=["datasets/GUI-Knowledge-Bench"]
```

---

## ğŸ“Š Run and Outputs

```bash
python Inference/inference_advanced.py \
  --yaml_dir Inference/configs/ModelConfigList/ConfigExamples/openai_gpt5_chat_model_config.yaml
```

**Outputs:**

* Results â†’ `FINAL_RESULT/.../ModelName/*.json`
* Logs â†’ `Inference/log/{timestamp}/`
* Includes: `config.yaml`, `config.json`, `error.jsonl`, `failed_jsons/`

---

## ğŸ§  Troubleshooting

* **Image not found** â†’ Check `.env` paths
* **Rate limit or timeout** â†’ Tune `kwargs.timeout`, `MaxWorker`
* **Tool schema failures** â†’ Ensure schema matches model capabilities

---

## ğŸ”§ How to Extend (Engines and Clients)

* Add new branch in `client_init(engine_type)` in `inference_advanced.py`
* Add per-ModelName handling in `eval_message()` if needed
* Keep schema consistent with target SDK

---

## ğŸ“ Notes

* Dataset license: **apache-2.0** (check before redistribution)
* Folder layout may vary; adjust `KnowledgeBenchDir` and `dataset_base_dir` accordingly.

</details>

---

<details>
<summary><b>ä¸­æ–‡ç‰ˆæœ¬ ğŸ‡¨ğŸ‡³</b></summary>

## ğŸ§© ç®€ä»‹

**GUI Knowledge Bench Runner** æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼° GUI å¤šæ¨¡æ€ç†è§£èƒ½åŠ›çš„ Python å·¥å…·åŒ…ï¼Œè¦†ç›–ä¸‰ç±»çŸ¥è¯†ä»»åŠ¡ï¼š

* **ç•Œé¢ç†è§£**ï¼šçŠ¶æ€ä¿¡æ¯ã€å¸ƒå±€è¯­ä¹‰ã€æ§ä»¶åŠŸèƒ½
* **äº¤äº’é¢„æµ‹**ï¼šåŠ¨ä½œç±»å‹ä¸å‚æ•°ã€åŠ¨ä½œæ•ˆæœï¼ˆç»“æœæˆªå›¾ï¼‰
* **æŒ‡ä»¤ç†è§£**ï¼šä»»åŠ¡å®Œæˆåˆ¤å®šä¸ä»»åŠ¡è§„åˆ’

å·¥å…·åŒ…é€šè¿‡è¯»å– YAML é…ç½®ç”Ÿæˆå¤šæ¨¡æ€æç¤ºï¼ˆå›¾ç‰‡ + æ–‡æœ¬ï¼‰ï¼Œè°ƒç”¨é€‰å®šæ¨¡å‹/APIï¼Œå¹¶ä¿å­˜ç»“æœä¸æ—¥å¿—ï¼Œä»¥å®ç°å¯å¤ç°çš„è¯„æµ‹ã€‚

---

## âš™ï¸ åŠŸèƒ½ç‰¹æ€§

* ä»»åŠ¡ç»“æ„æ¸…æ™°ï¼šç•Œé¢ç†è§£ã€äº¤äº’é¢„æµ‹ã€æŒ‡ä»¤ç†è§£
* å¤šæ¨¡æ€æç¤ºæ„é€ ï¼Œå¯é€‰è§†è§‰æ ‡æ³¨ä¸çŸ¥è¯†æç¤º
* OpenAI å…¼å®¹å¼•æ“è·¯ç”±ï¼ˆé€šä¹‰/Qwen æ¨¡å¼ã€é€šç”¨ä»£ç†ï¼‰
* å¹¶å‘æ‰§è¡Œä¸æ—¥å¿—æ±‡æ€»
* å¯è§†åŒ–æ ‡æ³¨ä¸åŠ¨ä½œç»˜åˆ¶å·¥å…·
* åŸºäºé…ç½®çš„æ¶ˆèå®éªŒä¸å¯å¤ç°è¿è¡Œ

---

## ğŸ“ ä»“åº“ç»“æ„

| è·¯å¾„                                              | æè¿°                               |
| ----------------------------------------------- | -------------------------------- |
| `.env`                                          | ç¯å¢ƒå˜é‡ï¼ˆAPI Keyã€æ•°æ®é›†è·¯å¾„ï¼‰              |
| `Inference/`                                    | æ ¸å¿ƒè¯„æµ‹ä¸å·¥å…·                          |
| `inference_advanced.py`                         | ä¸»å…¥å£ï¼šåŠ è½½é…ç½®ã€æ„é€ æç¤ºã€è°ƒç”¨æ¨¡å‹ã€ä¿å­˜ç»“æœ          |
| `tools/load_config_tools.py`                    | è¯»å– YAMLã€æšä¸¾æµ‹è¯•æ–‡ä»¶ã€æŒ‰ TestingScope è¿‡æ»¤ |
| `tools/message_gen_tools.py`                    | æ„é€ å¤šæ¨¡æ€æ¶ˆæ¯ä¸æ¶ˆè                       |
| `tools/draw_picture.py`                         | å¯è§†åŒ–æ ‡æ³¨ä¸åŠ¨ä½œç»˜åˆ¶                       |
| `configs/ModelConfigList/ConfigExamples/*.yaml` | æ¨¡å‹é…ç½®ç¤ºä¾‹                           |
| `log/{timestamp}/`                              | æ¯æ¬¡è¿è¡Œè‡ªåŠ¨ç”Ÿæˆæ—¥å¿—                       |
| `KnowledgeBench/`                               | è¯„æµ‹é¢˜ç›® JSON æ–‡ä»¶                     |
| `FINAL_RESULT/`                                 | ç»“æœè¾“å‡ºç›®å½•                           |

---

## ğŸ§° å®‰è£…ä¾èµ–

**Python 3.9+**

```bash
pip install pyyaml python-dotenv openai pydantic pillow opencv-python numpy ray
# æ•°æ®é›†ä¸‹è½½ç›¸å…³
pip install huggingface_hub datasets git-lfs
```

> æ³¨æ„ï¼š`git-lfs` éœ€ç³»ç»Ÿçº§å®‰è£…ã€‚

---

## ğŸ“¦ æ•°æ®å‡†å¤‡

**æ•°æ®é›†ï¼š** [KendrickShi/GUI-Knowledge-Bench](https://huggingface.co/datasets/KendrickShi/GUI-Knowledge-Bench)

ä¸‹è½½å®Œæˆåï¼š

* åœ¨ YAML ä¸­è®¾ç½® `KnowledgeBenchDir` æŒ‡å‘ JSON æµ‹è¯•æ–‡ä»¶ç›®å½•
* åœ¨ `.env` ä¸­è®¾ç½® `dataset_base_dir` ä¸ºåŒ…å«å›¾ç‰‡çš„ç›®å½•åˆ—è¡¨

**ä¸‹è½½æ–¹å¼ï¼š**

**1ï¸âƒ£ git-lfsï¼ˆæ¨èï¼‰**

```bash
git lfs install
git clone https://huggingface.co/datasets/KendrickShi/GUI-Knowledge-Bench datasets/GUI-Knowledge-Bench
```

**2ï¸âƒ£ huggingface_hubï¼ˆPythonï¼‰**

```python
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id="KendrickShi/GUI-Knowledge-Bench",
    repo_type="dataset",
    local_dir="datasets/GUI-Knowledge-Bench",
    local_dir_use_symlinks=False
)
```

**3ï¸âƒ£ datasets åº“**

```python
from datasets import load_dataset
ds = load_dataset("KendrickShi/GUI-Knowledge-Bench", split="train")
```

---

## ğŸŒ ç¯å¢ƒå˜é‡ (.env)

| å˜é‡                 | è¯´æ˜                                                           |
| ------------------ | ------------------------------------------------------------ |
| `deerapi_key`      | OpenAI å…¼å®¹ä»£ç† API Keyï¼ˆå¦‚ DeerAPIï¼‰                               |
| `deerapi_url`      | åŸºç¡€ URLï¼Œå¦‚ `https://api.deerapi.com/v1/`                       |
| `qwen_api_key`     | Qwenï¼ˆé€šä¹‰ï¼‰API Key                                              |
| `qwen_url`         | åŸºç¡€ URLï¼Œå¦‚ `https://dashscope.aliyuncs.com/compatible-mode/v1` |
| `dataset_base_dir` | å›¾ç‰‡æ ¹ç›®å½• JSON åˆ—è¡¨                                                |

---

## ğŸ§¾ é…ç½®æ–‡ä»¶ (YAML)

**å¿…å¡«å­—æ®µï¼š**

* `KnowledgeBenchDir`ï¼šè¯„æµ‹é¢˜ç›® JSON æ‰€åœ¨ç›®å½•
* `ModelName`ï¼šæ¨¡å‹åç§°ï¼ˆå¦‚ `gpt-5-chat-latest`ï¼‰
* `Engine`ï¼šæœåŠ¡æä¾›è€…è·¯ç”±é”®
* `ResultsDir`ï¼šè¾“å‡ºç›®å½•
* `thinking`ï¼šæ˜¯å¦è¾“å‡ºæ€è€ƒå­—æ®µ
* `MaxWorker`ï¼šæœ€å¤§å¹¶å‘æ•°
* `kwargs`ï¼šè°ƒç”¨å‚æ•°ï¼ˆ`max_tokens`, `temperature` ç­‰ï¼‰
* `ablation_options`ï¼šæ˜¯å¦å¯ç”¨è§†è§‰æç¤ºä¸çŸ¥è¯†æç¤º
* `TestingScope`ï¼šè¦è¯„æµ‹çš„å­ä»»åŠ¡

---

## ğŸ§® å¼•æ“ä¸æ¨¡å‹æ˜ å°„

å½“å‰æ”¯æŒï¼š

* **Engine: qwen** â†’ ä½¿ç”¨ `qwen_api_key + qwen_url`
* **Engine: deerapi_gpt** â†’ ä½¿ç”¨ `deerapi_key + deerapi_url`

ç‰¹æ®Šå¤„ç†æ¨¡å‹ï¼š

```python
["grok-4-0709", "claude-sonnet-4-20250514", "gemini-2.5-pro-preview-06-05"]
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

**YAML ç¤ºä¾‹ï¼š**

```yaml
KnowledgeBenchDir: datasets/GUI-Knowledge-Bench/questions
ModelName: qwen2.5-vl-7b-instruct
Engine: qwen
ResultsDir: FINAL_RESULT
thinking: false
MaxWorker: 4
kwargs:
  max_tokens: 1024
  temperature: 0.2
  top_p: 0.9
  timeout: 120
ablation_options:
  visual_prompt: true
  knowledge_prompt: true
TestingScope:
  - InterfacePerception
  - InteractionPrediction
  - InstructionUnderstanding
```

`.env` ç¤ºä¾‹ï¼š

```bash
dataset_base_dir=["datasets/GUI-Knowledge-Bench"]
```

---

## ğŸ“Š è¿è¡Œä¸è¾“å‡º

```bash
python Inference/inference_advanced.py --yaml_dir Inference/configs/ModelConfigList/ConfigExamples/openai_gpt5_chat_model_config.yaml
```

è¾“å‡ºï¼š

* ç»“æœï¼š`FINAL_RESULT/.../ModelName/*.json`
* æ—¥å¿—ï¼š`Inference/log/{timestamp}/`
* åŒ…å«ï¼š`config.yaml`ã€`config.json`ã€`error.jsonl`ã€`failed_jsons/`

---

## ğŸ§  å¸¸è§é—®é¢˜

* å›¾ç‰‡æ‰¾ä¸åˆ° â†’ æ£€æŸ¥ `.env` ä¸­è·¯å¾„
* é€Ÿç‡é™åˆ¶æˆ–è¶…æ—¶ â†’ è°ƒæ•´ `timeout` ä¸ `MaxWorker`
* å·¥å…·è°ƒç”¨é”™è¯¯ â†’ æ£€æŸ¥ schema æ˜¯å¦ä¸æ¨¡å‹èƒ½åŠ›åŒ¹é…

---

## ğŸ”§ æ‰©å±•æ–¹æ³•

* åœ¨ `inference_advanced.py` çš„ `client_init()` ä¸­æ·»åŠ æ–°åˆ†æ”¯
* è‹¥éœ€ç‰¹æ®Šå¤„ç†æ¨¡å‹ï¼Œå¯åœ¨ `eval_message()` æ·»åŠ é€»è¾‘
* ç¡®ä¿æ¶ˆæ¯ä¸å·¥å…· schema ä¸ SDK ä¸€è‡´

---

## ğŸ“ å¤‡æ³¨

* æ•°æ®é›†è®¸å¯è¯ï¼š**apache-2.0**
* æ–‡ä»¶å±‚çº§å¯èƒ½å˜åŒ–ï¼Œè¯·ç¡®è®¤è·¯å¾„è®¾ç½®æ­£ç¡®ã€‚

</details>
